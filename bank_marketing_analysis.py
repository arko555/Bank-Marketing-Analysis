# -*- coding: utf-8 -*-
"""Bank_Marketing_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JJ7grOfXrrCSuWF_Lmhdr6QjqNrWReoy
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn import metrics
# %matplotlib inline
plt.style.use('ggplot')

from google.colab import files
uploaded = files.upload()

!ls

bank=pd.read_csv('bank.csv')
bank.head()

bank.isna().sum() #check null values
bank.shape
bank.dtypes

bank.describe(include='all')

col_name=['age','duration','balance']

fig, ax = plt.subplots(len(col_name), figsize=(8,20))

for i,val in enumerate(col_name):
  sns.boxplot(x=bank[val],ax=ax[i])

plt.show()

#col_name=['age','duration','balance']

fig, ax = plt.subplots(len(col_name), figsize=(8,20))

for i,val in enumerate(col_name):
  sns.distplot(bank[val],hist=True,ax=ax[i])

plt.show()

bank['job'].unique()

bank['job'][bank['deposit']=='yes'].value_counts()

bank['job'].value_counts()

bank_data=bank.copy()

bank_data['job']=bank_data['job'].replace(['management', 'admin.'], 'white_collar')
bank_data['job'] = bank_data['job'].replace(['services','housemaid'], 'pink-collar')
bank_data['job'] = bank_data['job'].replace(['retired', 'student', 'unemployed', 'unknown'], 'other')

bank_data['job'].value_counts()

bank_data['poutcome'].value_counts()

bank_data['poutcome']=bank_data['poutcome'].replace(['other'], 'unknown')
bank_data['poutcome'].value_counts()

bank_data.drop('contact',axis=1,inplace=True)

bank_data['default'].unique()
b1=bank_data.select_dtypes(include=int)
sns.pairplot(b1)

bank_data['default']=bank_data['default'].map( {'yes':1, 'no':0} )
bank_data['housing']=bank_data['housing'].map( {'yes':1, 'no':0} )
bank_data['loan']=bank_data['loan'].map( {'yes':1, 'no':0} )
bank_data['deposit']=bank_data['deposit'].map( {'yes':1, 'no':0} )
# converted to categorical values from string

print("No of users never contacted", len(bank_data['pdays']=='-1'))
print("max gap in contact", bank_data['pdays'].max())

bank_data.loc[bank_data['pdays']==-1, 'pdays'] = 10000 #turning -1 to 10000 so that its almost negligible in effect

bank_data['recent_pdays']=np.where(bank_data['pdays'],1/bank_data.pdays,1/bank_data.pdays)
bank_data.drop('pdays',axis=1,inplace=True)

bank_data.tail()

bank_dummies=pd.get_dummies(data=bank_data, columns=['job','marital','education','poutcome'], prefix=['job','marital','education','poutcome'])

bank_dummies.head()

bank_dummies.describe()

bank_dummies.plot(kind='scatter',x='age',y='balance')

bank_dummies[bank_dummies['duration']<=1000].plot(kind='hist',x='poutcome_success',y='duration')

bank_dummies[bank_dummies['deposit']== 1 ].describe()

# People signed up to a term deposite having a personal loan (loan_cat) and housing loan (housing_cat)

len(bank_dummies[(bank_dummies['deposit']==1) & (bank_dummies['loan'] == 1 ) & (bank_dummies['housing'] == 1)])

# People signed up to a term deposite with a credit default 
len(bank_dummies[(bank_dummies['deposit']==1) & (bank_dummies['default'] == 1 )])

plt.figure(figsize=(10,6))
sns.countplot(x='job', hue='deposit', data=bank_data)

plt.figure(figsize=(10,6))
sns.barplot(x='poutcome', y='duration', data=bank_data)

corr=bank_dummies.corr()
plt.figure(figsize=(15,15))
cmap = sns.diverging_palette(220, 10, as_cmap=True)
sns.heatmap(corr,xticklabels=corr.columns.values, yticklabels=corr.columns.values,cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={"shrink": .82})
plt.title('Heatmap of Correlation Matrix')

corr_deposite = pd.DataFrame(corr['deposit'].drop('deposit'))
corr_deposite.sort_values(by = 'deposit', ascending = False)

x=bank_dummies.drop(['deposit','day','month'],axis=1)
y=bank_dummies['deposit']

data_train, data_test, label_train, label_test = train_test_split(x, y, test_size = 0.2, random_state = 50)
data_train

# Decision tree with depth = 6
dt6 = tree.DecisionTreeClassifier(random_state=1, max_depth=6)
dt6.fit(data_train, label_train)

dt6_score_train = dt6.score(data_train, label_train)
print("Training score: ",dt6_score_train)

dt6_score_test = dt6.score(data_test, label_test)
print("Testing score: ",dt6_score_test)

dt6.classes_
from sklearn.tree import export_graphviz
import pydotplus
from io import StringIO
from IPython.display import Image

features = data_train.columns.tolist()

tree_depth_6=StringIO()

tree.export_graphviz(dt6, out_file=tree_depth_6, feature_names=features)
graph=pydotplus.graph_from_dot_data(tree_depth_6.getvalue())

Image(graph.create_png())

dt6.classes_

features=data_train.columns.to_list()
features

fi=dt6.feature_importances_
l=len(features)

for i in range(0,l):
  print("%s=%s" % (features[i],fi[i]))

# since duration turns out to be the most important feature hence we look into its descriptive statistics
print("Mean duration   : ", data_train.duration.mean())
print("Maximun duration: ", data_train.duration.max())
print("Minimum duration: ", data_train.duration.min())

